{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack and anomaly detection in IoT sensors in IoT sites using machine learning approaches\n",
    "\n",
    "Article information:\n",
    "* Authors: Mahmudul Hasan, Milon Islam, Ishrak Islam Zarif and M.M.A.Hashem\n",
    "* Publication: 20 May 2019\n",
    "* DOI: https://doi.org/10.1016/j.iot.2019.100059\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Attack and anomaly detection in the Internet of Things (IoT) infrastructure is a rising concern in the domain of IoT.\n",
    "With the increased use of IoT infrastructure in every domain, threats and attacks in these infrastructures are also growing commensurately.\n",
    "Denial of Service, Data Type Probing, Malicious Control, Malicious Operation, Scan, Spying and Wrong Setup are such attacks and anomalies which can cause an IoT system failure.\n",
    "In this paper, performances of several machine learning models have been compared to predict attacks and anomalies on the IoT systems accurately.\n",
    "The machine learning (ML) algorithms that have been used here are Logistic Regression (LR), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), and Artificial Neural Network (ANN).\n",
    "The evaluation metrics used in the comparison of performance are accuracy, precision, recall, f1 score, and area under the Receiver Operating Characteristic Curve.\n",
    "The system obtained 99.4% test accuracy for Decision Tree, Random Forest, and ANN.\n",
    "Though these techniques have the same accuracy, other metrics prove that Random Forest performs comparatively better.\n",
    "\n",
    "## Dataset description\n",
    "\n",
    "The open source dataset was collected from [kaggle](https://www.kaggle.com/francoisxa/ds2ostraffictraces) provided by [Pahl et al.](https://ieeexplore.ieee.org/abstract/document/8584985).\n",
    "They have created a virtual IoT environment using Distributed Smart Space Orchestration System (DS2OS) for producing synthetic data.\n",
    "Their architecture is a collection of micro-services which communicates with each other using the Message Queuing Telemetry Transport (MQTT) protocol.\n",
    "In the dataset, there are 357,952 samples and 13 features.\n",
    "The dataset has 347,935 Normal data and 10,017 anomalous data and contains eight classes which were classified.\n",
    "Features “Accessed Node Type” and “Value” have 148 and 2050 missing data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas to load the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# graphics\n",
    "from pylab import rcParams\n",
    "%matplotlib inline \n",
    "rcParams['figure.figsize'] = 8, 8\n",
    "\n",
    "# load dataset\n",
    "dataset_file = 'dataset/mainSimulationAccessTraces.csv'\n",
    "df = pd.read_csv(dataset_file, header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack description\n",
    "\n",
    "1. **Denial of Service (DoS):** the DoS attack is caused by having too many unwanted traffic in a single source or receiver. The attacker sends too many ambiguous packets to flood out the target and make its services unavailable to other services.\n",
    "\n",
    "2. **Data Type Probing (D.P):** in this case, a malicious node writes different data type than intended data type. \n",
    "\n",
    "3. **Malicious Control (M.C):** with software vulnerabilities sometimes the attacker can gain a valid session key or somehow capture network traffic. In this way, malicious one can control the whole system.\n",
    "\n",
    "4. **Malicious Operation (M.O):** Malicious Operations are generally caused by malware. Malware means decoy activity which distracts the original operation. Device’s performances can negatively be affected by this malicious operation.\n",
    "\n",
    "5. **Scan(SC):** sometimes the data is acquired through hardware by scanning the system, and in this process sometimes the data can get corrupted.\n",
    "\n",
    "6. **Spying (SP):** by Spying, the attacker exploits the vulnerabilities of the system, and they use a backdoor channel to break into the system and discovers important information. In some cases, they manipulate data causing great hamper to the whole system.\n",
    "\n",
    "7. **Wrong Setup (W.S):** the data may also get disrupted by the wrong system setup.\n",
    "\n",
    "8. **Normal(NL):** if the data is entirely correct and accurate, then the data is called normal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statistics from the dataset\n",
    "print('Dataset Information:')\n",
    "print(df.info())\n",
    "print('------------------------------------------------------')\n",
    "print('Target variable frequency:')\n",
    "count = df['normality'].value_counts() \n",
    "count.plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the previous image, the dataset is quite unbalanced.\n",
    "Most of the interactions between devices within the simulation are considered normal.\n",
    "To have a better view of the target variable distribution, the next plot does no contain the samples classified as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Target variable frequency:')\n",
    "non_normal_df = df[df['normality'] != 'normal']\n",
    "count = non_normal_df['normality'].value_counts() \n",
    "count.plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after removing the samples classified as normal, the dataset remains unbalanced.\n",
    "The authors did not address this issue within the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequencies of occurences in IoT communication. \n",
    "* (a) Source Type\n",
    "* (b) Destination Type\n",
    "* (c) Source Location\n",
    "* (d) Destination Location\n",
    "* (e) Accessed Node\n",
    "* (f) Operation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abbreviations for values found in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceTypeValues = df.sourceType.dropna().unique()\n",
    "shortSourceTypeName = ['lc', 'ms', 'ss', 'bs', 'ds', 'ts', 'ws', 'sp']\n",
    "\n",
    "new_keys = dict(zip(sourceTypeValues, shortSourceTypeName))\n",
    "# display(new_keys)\n",
    "\n",
    "sourceLocationValues = df.sourceLocation.dropna().unique()\n",
    "shortSourceLocationName = ['bp', 'dr', 'bc', 'kt', 'gg', 'bt', 'lr', 'wr', 'bd', 'et', 'sr', 'r1', 'r2', 'r3', \n",
    "                           'r4', 'r5', 'r6', 'r7', 'r9', 'r8', 'r10']\n",
    "\n",
    "new_keys2 = dict(zip(sourceLocationValues, shortSourceLocationName))\n",
    "# display(new_keys2)\n",
    "\n",
    "accessedNodeValues = df.accessedNodeType.dropna().unique()\n",
    "shortAccessedNodeName = ['lc', 'ms', 'ss', 'bl', 'nb', 'bs', 'ds', 'ts', 'ws', 'tt', 'sp', 'cp']\n",
    "\n",
    "new_keys3 = dict(zip(accessedNodeValues, shortAccessedNodeName))\n",
    "# display(new_keys3)\n",
    "\n",
    "operationValues = df.operation.dropna().unique()\n",
    "shortOperationName = ['rs', 'wr', 'rd', 'sb', 'ls']\n",
    "# sb = subscribe [Não está no artigo]\n",
    "\n",
    "new_keys4 = dict(zip(operationValues, shortOperationName))\n",
    "# display(new_keys4)\n",
    "\n",
    "# Creates short name dictionary for values in dataset\n",
    "keys_dict = {**new_keys, **new_keys2, **new_keys3, **new_keys4}\n",
    "import operator\n",
    "keys_dict = dict(sorted(keys_dict.items(), key=operator.itemgetter(1)))\n",
    "print('The following cointains abbreviations for the data found in the dataset:')\n",
    "display(keys_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFrequencyTable(dict_, x_label, y_label = 'Number of Ocurrences'):    \n",
    "    temp_dict = {}\n",
    "\n",
    "#     Creates a dictionary v, k with original dictionary values and short names\n",
    "    for key, value in dict_.items():\n",
    "        temp_dict[dict_[key]] = keys_dict[key]\n",
    "\n",
    "#     Converts temp_dict keys to value and vice-versa\n",
    "    new_sourceType = dict((v,k) for k,v in temp_dict.items())\n",
    "\n",
    "#     Creates plot figure\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.bar(new_sourceType.keys(), new_sourceType.values())\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Source Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = df.sourceType.value_counts()\n",
    "display(dict_)\n",
    "\n",
    "x_label = 'Source Type'\n",
    "\n",
    "createFrequencyTable(dict_, x_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Destination Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_ = df.destinationServiceType.value_counts()\n",
    "display(dict_)\n",
    "\n",
    "x_label = 'Destination Type'\n",
    "\n",
    "createFrequencyTable(dict_, x_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Source Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = df.sourceLocation.value_counts()\n",
    "display(dict_)\n",
    "\n",
    "x_label = 'Source Location'\n",
    "\n",
    "createFrequencyTable(dict_, x_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Destination Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_ = df.destinationLocation.value_counts()\n",
    "display(dict_)\n",
    "\n",
    "x_label = 'Destination Location'\n",
    "\n",
    "createFrequencyTable(dict_, x_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Accessed Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = df.accessedNodeType.value_counts()\n",
    "display(dict_)\n",
    "\n",
    "x_label = 'Accessed Node'\n",
    "\n",
    "createFrequencyTable(dict_, x_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = df.operation.value_counts()\n",
    "display(dict_)\n",
    "\n",
    "x_label = 'Operation'\n",
    "\n",
    "createFrequencyTable(dict_, x_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Any machine learning research requires exploratory data analysis and data observation.\n",
    "The first task in this research was to make the dataset feed-able to any classifier.\n",
    "So for this reason, the first step was to handle the missing data. \n",
    "\n",
    "In the dataset, **Accessed Node Type** column and **Value** column contain missing values due to anomaly raised in data transferring. \n",
    "From these two features, **Accessed Node Type** feature has categorical values on the other hand **Value** feature has continuous values. \n",
    "\n",
    "**Accessed Node Type** feature has 148 rows containing _NaN_ value depicted as _Not a Number_, and the corresponding class or label of that row are found to be anomalous. As the **Accessed Node Type** feature is categorical and removing these 148 rows might cause loss of valuable data, so the _NaN_ value in **Accessed Node Type** is replaced with the _Malicious_ value.\n",
    "\n",
    "Similarly, **Value** column also contains some unexpected data which are not continuous values. \n",
    "These unexpected values are transformed into meaningful continuous values that assist the classifiers to have better accuracy.\n",
    "Unexpected values _False_, _True_, _Twenty_ and _none_ in the **Value** feature are replaced by meaningful values _0.0_, _1.0_, _20.0_ and _0.0_, respectively.\n",
    "\n",
    "**Attention:**\n",
    "\n",
    "In where we describe aditional preprocessing steps that where not mentioned on the work, but are necessary to clean the dataset.\n",
    "Some values in the column **Value** are missing or are strings of this type: \"org.ds2os.vsl.core.utils.AddressParameters@181ae4a8\"\n",
    "\n",
    "Since the authors want to convert the column **Value** to numerical, the following strategy was applied:\n",
    "1. All missing values where replaces with 0 \n",
    "2. Select all **Values** that start with \"org.\"\n",
    "3. Split the string into to parts by the \"@\" character\n",
    "4. Convert the second part into a numerical value (base16 convertion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix missing Accessed Node Type\n",
    "df = df.fillna({'accessedNodeType': 'Malicious'})\n",
    "\n",
    "# Fix the malformated values in column Value\n",
    "df = df.fillna({'value': 0.0})\n",
    "replace_values = {'true': 1.0, 'false': 0.0, 'twenty': 20.0, 'none': 0.0}\n",
    "df = df.replace({'value':replace_values})\n",
    "\n",
    "# Fix other errors not mentioned on the paper\n",
    "df.loc[df.value.str.contains('^org').fillna(False), 'value'] = df[df.value.str.contains('^org').fillna(False)]['value'].apply(lambda x: int(x.split('@')[1],16))\n",
    "\n",
    "# Replace the names of the target variable to be consistent with the paper\n",
    "replace_values={'anomalous(DoSattack)':'DoS', 'anomalous(scan)': 'SC', 'anomalous(malitiousControl)':'M.C',\n",
    "               'anomalous(malitiousOperation)': 'M.O', 'anomalous(spying)':'SP', 'anomalous(dataProbing)':'D.P',\n",
    "               'anomalous(wrongSetUp)':'W.S', 'normal':'NL'}\n",
    "df = df.replace({'normality':replace_values})\n",
    "\n",
    "# Check for NaN values\n",
    "missing = df.isnull().values.any()\n",
    "print('Missing Values ? {}'.format(missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "For feature selection, no machine learning approach has been taken here like Pahl et al. because this will not have any significant impact on data analysis. Besides this timestamp column from the dataset has been removed as it has a minimal correlation to the dataset’s predictor variable normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('timestamp', 1)\n",
    "print('Dataset Information:')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next vital task is to converting nominal categorical data into vectors. Categorical data can be converted into vectors in many ways.\n",
    "**Label Encoding** and **One Hot Encoding** is prevalent among them. \n",
    "In this research **label encoding** technique have been used to convert the data into a feature vector.\n",
    "\n",
    "Furthermore, the **Value** column needs to be converted into numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset datatypes (before transformation):')\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert value to float\n",
    "df['value'] = pd.to_numeric(df['value'])\n",
    "\n",
    "# Convert target variable to categorical\n",
    "df['normality'] = df['normality'].astype('category')\n",
    "\n",
    "# Apply label enconding to the remaining columns\n",
    "# The label encoding was applied directly with pandas\n",
    "columns=['sourceID', 'sourceAddress', 'sourceType',\n",
    "'sourceLocation', 'destinationServiceAddress', 'destinationServiceType',\n",
    "'destinationLocation', 'accessedNodeAddress', 'accessedNodeType', 'operation']\n",
    "\n",
    "for column in columns:\n",
    "    df[column] = df[column].astype('category')\n",
    "    df[column] = df[column].cat.codes\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('Dataset datatypes (after transformation):')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "The authors tested 5 different models:\n",
    "1. Logistic Regression       (LR)\n",
    "2. Support Vector Machine    (SVM)\n",
    "3. Decision Tree             (DT)\n",
    "4. Random Forest             (RF)\n",
    "5. Artificial Neural Network (ANN)\n",
    "\n",
    "However, the specific configuration for each model was not discussed in the work. As such we try to reproduce their work with the default configurations whenever possible.\n",
    "\n",
    "The dataset is mainly composed of categorical data (that was transformed using label encoding). The column **Value** is the only one that is numerical (apart form **Timestamp** that was removed previously). All the models issued a warning when we tried to fit it without normalizing the numerical feature.\n",
    "That step was not stated within the work, but we assume that it may have been done.\n",
    "\n",
    "Regarding the performance evaluation, the authors used five-fold cross-validation and computed the following metrics:\n",
    "1. Accuracy\n",
    "2. Precision\n",
    "3. Recall\n",
    "4. F1 Score \n",
    "5. ROC curve\n",
    "\n",
    "There was no sufficient detail regarding how the performance metrics were computed. For this work we assumed that the confusion matrix from each fold is added to the previous one, the performance metrics are then computed for each class individually and finally macro-averaging ie computed to reach the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to compute performance metrics\n",
    "def decompose_cm(cm, c=0):\n",
    "    TP = cm[c,c]\n",
    "    tmp = np.delete(np.delete(cm, c, 0), c, 1)\n",
    "    TN = np.sum(tmp)\n",
    "    FP = np.sum(cm[c, :]) - TP\n",
    "    FN = np.sum(cm[:, c]) - TP\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def compute_performance_metrics(tp, tn, fp, fn):\n",
    "    if (tp+tn) == 0.0:\n",
    "        return 0,0,0,0\n",
    "    else:\n",
    "        acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "        if tp == 0.0:\n",
    "            return acc, 0, 0, 0\n",
    "        else:\n",
    "            pre = tp/(tp+fp)\n",
    "            rec = tp/(tp+fn)\n",
    "            f1 = (2*tp)/(2*tp + fp + fn)\n",
    "    return acc, pre, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the preprocessing libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert pandas dataframe into numpy arrays\n",
    "columns=['sourceID', 'sourceAddress', 'sourceType', 'sourceLocation', \n",
    "'destinationServiceAddress', 'destinationServiceType', 'destinationLocation',\n",
    "'accessedNodeAddress', 'accessedNodeType', 'operation', 'value']\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df.normality)\n",
    "y=le.transform(df.normality)\n",
    "X = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library used to speedup computation\n",
    "from joblib import parallel_backend\n",
    "\n",
    "# Import the necessary models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Import the stratified KFold library\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# RoC related libraries\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Prepare the dataset to be used in 5-fold cross validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# List of models names and models algorithms\n",
    "models = [\n",
    "    ('LR',  SGDClassifier(loss='log')),\n",
    "    ('SVM', SGDClassifier(loss='hinge')),\n",
    "    ('DT',  DecisionTreeClassifier()),\n",
    "    ('RF',  RandomForestClassifier()),\n",
    "    ('ANN', MLPClassifier())\n",
    "]\n",
    "\n",
    "# Dictionary that will contain the confusion matrix for each model\n",
    "cm = {}\n",
    "\n",
    "# Dictionary that will contain the RoC scores\n",
    "roc = {}\n",
    "\n",
    "# fold counter\n",
    "k=0\n",
    "\n",
    "# FPR for ROC curve\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Use the parallel backend to speedup the fit operation\n",
    "with parallel_backend('threading'):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # For each fold\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        k += 1\n",
    "        print('K-Fold: {}'.format(k))\n",
    "    \n",
    "        X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        #Scale only the numerical feature (value)\n",
    "        feature = X_train[['value']]\n",
    "        scaler.fit(feature.values)\n",
    "        feature = scaler.transform(feature.values)\n",
    "        X_train.loc[:, 'value'] = feature\n",
    "        feature = scaler.transform(X_test[['value']].values)\n",
    "        X_test.loc[:, 'value'] = feature\n",
    "    \n",
    "        # For each model\n",
    "        for model in models:\n",
    "            print('\\tModel: {}'.format(model[0]))\n",
    "            model[1].fit(X_train, y_train)\n",
    "            y_pred = model[1].predict(X_test)\n",
    "            \n",
    "            # Store the information for the confusion matrix\n",
    "            if model[0] in cm:\n",
    "                cm[model[0]] = np.add(cm[model[0]], confusion_matrix(y_test, y_pred))\n",
    "            else:\n",
    "                cm[model[0]] = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            # Store the information for the RoC curve\n",
    "            tpr = []\n",
    "            \n",
    "            for i in range (0, len(cm[model[0]])):\n",
    "                f, t, _ = roc_curve(y_test, y_pred, pos_label=i)\n",
    "                r = auc(f, t)\n",
    "                interp_tpr = np.interp(mean_fpr, f, t)\n",
    "                interp_tpr[0] = 0.0\n",
    "                tpr.append(interp_tpr)\n",
    "            \n",
    "            if model[0] in roc:\n",
    "                roc[model[0]]['tpr'].append(tpr)\n",
    "            else:\n",
    "                d = {}\n",
    "                d['tpr'] = [tpr]\n",
    "                roc[model[0]] = d\n",
    "\n",
    "# Compute the mean values for TPR\n",
    "for model in models:\n",
    "    d = roc[model[0]]\n",
    "    d['tpr'] = np.array(d['tpr']).mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluation  Classifiers')\n",
    "print('Metrics     LR    SVM   DT    RF    ANN')\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "# For all models\n",
    "for model in models:\n",
    "    acc_score = pre_score = rec_score = f1_score = 0\n",
    "    \n",
    "    # For all classes\n",
    "    for i in range(0, len(cm[model[0]])):\n",
    "        tp, tn, fp, fn = decompose_cm(cm[model[0]], i)\n",
    "        a, p, r, f  = compute_performance_metrics(tp, tn, fp, fn)\n",
    "        acc_score += a\n",
    "        pre_score += p\n",
    "        rec_score += r\n",
    "        f1_score  += f\n",
    "    \n",
    "    # Compute macro average\n",
    "    acc_score /= len(cm[model[0]])\n",
    "    pre_score /= len(cm[model[0]])\n",
    "    rec_score /= len(cm[model[0]])\n",
    "    f1_score  /= len(cm[model[0]])\n",
    "    \n",
    "    #\n",
    "    accuracy.append(acc_score)\n",
    "    precision.append(pre_score)\n",
    "    recall.append(rec_score)\n",
    "    f1.append(f1_score)\n",
    "\n",
    "print('Accuracy    {:4.3f} {:4.3f} {:4.3f} {:4.3f} {:4.3f}'.format(*accuracy))\n",
    "print('Precision   {:4.3f} {:4.3f} {:4.3f} {:4.3f} {:4.3f}'.format(*precision))\n",
    "print('Recall      {:4.3f} {:4.3f} {:4.3f} {:4.3f} {:4.3f}'.format(*recall))\n",
    "print('F1 score    {:4.3f} {:4.3f} {:4.3f} {:4.3f} {:4.3f}'.format(*f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# For all models\n",
    "labels = le.inverse_transform(list(range(0, len(cm[model[0]]))))\n",
    "for model in models:\n",
    "    # Normalise\n",
    "    normalized_cm = cm[model[0]].astype('float') / cm[model[0]].sum(axis=1)[:, np.newaxis]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=normalized_cm, display_labels=labels)\n",
    "    disp.plot(cmap='cividis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For all models\n",
    "for model in models:\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    tpr = roc[model[0]]['tpr']\n",
    "    # For all classes\n",
    "    for i in range (0, len(cm[model[0]])):\n",
    "        mean_tpr = tpr[i]\n",
    "        # Compute the mean auc based on the mean FPR ant TPR\n",
    "        mean_auc = mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        plt.plot(mean_fpr, mean_tpr,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(le.inverse_transform([i]), mean_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC {}'.format(model[0]))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
