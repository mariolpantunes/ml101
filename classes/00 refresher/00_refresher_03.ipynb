{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimization\n",
    "\n",
    "Optimization refers to a procedure for finding the input parameters or arguments to a function that result in the minimum or maximum output of the function.\n",
    "\n",
    "The most common type of optimization problems encountered in machine learning are **continuous function optimization**, where the input arguments to the function are real-valued numeric values, e.g. floating point values. The output from the function is also a real-valued evaluation of the input values.\n",
    "\n",
    "We might refer to problems of this type as continuous function optimization, to distinguish from functions that take discrete variables and are referred to as combinatorial optimization problems.\n",
    "\n",
    "There are many different types of optimization algorithms that can be used for continuous function optimization problems, and perhaps just as many ways to group and summarize them.\n",
    "\n",
    "Perhaps the major division in optimization algorithms is whether the objective function can be differentiated at a point or not. That is, whether the first derivative (gradient or slope) of the function can be calculated for a given candidate solution or not. This partitions algorithms into those that can make use of the calculated gradient information and those that do not:\n",
    "\n",
    "- Algorithms that use derivative information.\n",
    "- Algorithms that do not use derivative information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable Objective Function\n",
    "\n",
    "A differentiable function is a function where the derivative can be calculated for any given point in the input space.\n",
    "\n",
    "The derivative of a function for a value is the rate or amount of change in the function at that point. It is often called the slope.\n",
    "\n",
    "- **First-Order Derivative**: Slope or rate of change of an objective function at a given point.\n",
    "\n",
    "The derivative of the function with more than one input variable (e.g. multivariate inputs) is commonly referred to as the gradient.\n",
    "\n",
    "- **Gradient**: Derivative of a multivariate continuous objective function.\n",
    "\n",
    "A derivative for a multivariate objective function is a vector, and each element in the vector is called a partial derivative, or the rate of change for a given variable at the point assuming all other variables are held constant.\n",
    "\n",
    "- **Partial Derivative**: Element of a derivative of a multivariate objective function.\n",
    "\n",
    "We can calculate the derivative of the derivative of the objective function, that is the rate of change of the rate of change in the objective function. This is called the second derivative.\n",
    "\n",
    "- **Second-Order Derivative**: Rate at which the derivative of the objective function changes.\n",
    "\n",
    "For a function that takes multiple input variables, this is a matrix and is referred to as the Hessian matrix.\n",
    "\n",
    "- **Hessian matrix**: Second derivative of a function with two or more input variables.\n",
    "\n",
    "Simple differentiable functions can be optimized analytically using calculus. Typically, the objective functions that we are interested in cannot be solved analytically.\n",
    "\n",
    "Optimization is significantly easier if the gradient of the objective function can be calculated, and as such, there has been a lot more research into optimization algorithms that use the derivative than those that do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First-Order Algorithms\n",
    "\n",
    "First-order optimization algorithms explicitly involve using the first derivative (gradient) to choose the direction to move in the search space.\n",
    "\n",
    "The procedures involve first calculating the gradient of the function, then following the gradient in the opposite direction (e.g. downhill to the minimum for minimization problems) using a step size (also called the learning rate).\n",
    "\n",
    "The step size is a hyperparameter that controls how far to move in the search space, unlike “local descent algorithms” that perform a full line search for each directional move.\n",
    "\n",
    "A step size that is too small results in a search that takes a long time and can get stuck, whereas a step size that is too large will result in zig-zagging or bouncing around the search space, missing the optima completely.\n",
    "\n",
    "The **Gradient Descent** uses the following update rule:\n",
    "$$\n",
    "x_{k+1} = x_{k}-\\alpha \\times \\nabla F(x_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import celluloid\n",
    "from celluloid import Camera\n",
    "\n",
    "\n",
    "class LinearRegressioner(object):\n",
    "    def __init__(self, w=1, b=1, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.w = np.array([[w]])\n",
    "        self.b = np.array([b])\n",
    "\n",
    "    def cost(self, x, y):\n",
    "        pred = x@self.w + self.b\n",
    "        e = y-pred\n",
    "        return np.mean(e**2)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        pred = x@self.w + self.b\n",
    "        e = y-pred\n",
    "        dJ_dw = (np.mean(e*(-2*x), axis=0))\n",
    "        dJ_db = (np.mean(e*(-2), axis=0))\n",
    "        self.w = (self.w.T - self.lr * dJ_dw).T\n",
    "        self.b = (self.b - self.lr * dJ_db)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return x@self.w.T + self.b\n",
    "\n",
    "    def params(self):\n",
    "        return (self.w, self.b)\n",
    "\n",
    "\n",
    "x_train = np.array([[1], [2], [4], [5], [6], [7]])\n",
    "\n",
    "y_train = np.array([[4], [-12], [3], [-11], [-5], [-17]])\n",
    "\n",
    "w_list = []  # for weight values\n",
    "b_list = []  # for biases\n",
    "c_list = []  # for cost values\n",
    "ys_list = []  # prediction on xs\n",
    "cl_list = []  # y values for x_train\n",
    "\n",
    "xs = np.array([\n",
    "    [-3],\n",
    "    [10]\n",
    "])\n",
    "\n",
    "model = LinearRegressioner(w=3, b=-1, lr=0.001)\n",
    "\n",
    "for i in tqdm.tqdm(range(10000)):\n",
    "    w_list.append(model.params()[0])\n",
    "    b_list.append(model.params()[1])\n",
    "    c_list.append(model.cost(x_train, y_train))\n",
    "    ys_list.append(model.predict(xs).T)\n",
    "    cl_list.append(model.predict(x_train).T)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "def cost_3d(x, y, w, b):\n",
    "    pred = x @ w.T + b\n",
    "    e = y-pred\n",
    "    return np.mean(e**2)\n",
    "\n",
    "\n",
    "ws = np.linspace(-5, 5.0, 10)\n",
    "bs = np.linspace(-5, 5, 10)\n",
    "M, B = np.meshgrid(ws, bs)\n",
    "\n",
    "# determine costs for each pair of w and b\n",
    "# cost_3d() only accepts wp and bp as matrices.\n",
    "zs = np.array([cost_3d(x_train, y_train, np.array([[wp]]), np.array([[bp]]))\n",
    "              for wp, bp in zip(np.ravel(M), np.ravel(B))])\n",
    "Z = zs.reshape(M.shape)\n",
    "\n",
    "# Define which epochs/data points to plot\n",
    "a = np.arange(0, 50, 1).tolist()\n",
    "b = np.arange(50, 100, 5).tolist()\n",
    "c = np.arange(100, 10000, 200).tolist()\n",
    "p = a+b+c  # points we want to plot\n",
    "\n",
    "# Turn lists into arrays\n",
    "w = np.array(w_list).flatten()\n",
    "b = np.array(b_list).flatten()\n",
    "c = np.array(c_list).flatten()\n",
    "ys = np.array(ys_list)\n",
    "p = np.array(p)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_title(\"Linear fit\", fontsize=30)\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.set_title(\"Cost function\", fontsize=30)\n",
    "ax2.view_init(elev=20., azim=145)\n",
    "camera = Camera(fig)\n",
    "\n",
    "for i in tqdm.tqdm(p):\n",
    "    leg = ax1.plot(xs.T.flatten(), ys[i].flatten(), color='r', label=str(i))\n",
    "    ax1.vlines(x_train.T, ymin=y_train.T,\n",
    "               ymax=cl_list[i], linestyle=\"dashed\", color='r', alpha=0.3)\n",
    "    ax1.scatter(x_train, y_train, color='b', marker='x', s=44)\n",
    "    ax1.legend(leg, [f'epochs: {i}'], loc='upper right', fontsize=15)\n",
    "    ax1.set_xlabel(\"x\", fontsize=25, labelpad=10)\n",
    "    ax1.set_ylabel(\"y\", fontsize=25, labelpad=10)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax1.set_ylim([-20, 10])\n",
    "\n",
    "    ax2.plot_surface(M, B, Z, rstride=1, cstride=1, color='b', alpha=0.35)  # create surface plot\n",
    "    ax2.scatter(w[i], b[i], c[i], marker='o', s=12**2, color='orange')\n",
    "    ax2.set_xlabel(\"w\", fontsize=25, labelpad=10)\n",
    "    ax2.set_ylabel(\"b\", fontsize=25, labelpad=10)\n",
    "    # negative value for labelpad places z-label left of z-axis.\n",
    "    ax2.set_zlabel(\"costs\", fontsize=25, labelpad=-35)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax2.plot(w[0:i], b[0:i], c[0:i], linestyle=\"dashed\", linewidth=2, color=\"grey\")  # (dashed) lineplot\n",
    "\n",
    "    plt.tight_layout()\n",
    "    camera.snap()\n",
    "\n",
    "animation = camera.animate(interval=5, repeat=False, repeat_delay=500)\n",
    "animation.save('../figs/SimpleLinReg_3.gif', writer='imagemagick')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient descent](../figs/SimpleLinReg_3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second-Order Algorithms\n",
    "\n",
    "Second-order optimization algorithms explicitly involve using the second derivative (Hessian) to choose the direction to move in the search space.\n",
    "\n",
    "These algorithms are only appropriate for those objective functions where the Hessian matrix can be calculated or approximated.\n",
    "\n",
    "The **Netwon Method** uses the following update rule:\n",
    "$$\n",
    "x_{k+1} = x_k - \\frac{f'(x_k)}{f''(x_k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Newton Method](../figs/NewtonIteration_Ani.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Differential Objective Function\n",
    "\n",
    "Optimization algorithms that make use of the derivative of the objective function are fast and efficient.\n",
    "\n",
    "Nevertheless, there are objective functions where the derivative cannot be calculated, typically because the function is complex for a variety of real-world reasons. Or the derivative can be calculated in some regions of the domain, but not all, or is not a good guide.\n",
    "\n",
    "Some difficulties on objective functions for the classical algorithms described in the previous section include:\n",
    "- No analytical description of the function (e.g. simulation).\n",
    "- Multiple global optima (e.g. multimodal).\n",
    "- Stochastic function evaluation (e.g. noisy).\n",
    "- Discontinuous objective function (e.g. regions with invalid solutions).\n",
    "\n",
    "As such, there are optimization algorithms that do not expect first- or second-order derivatives to be available.\n",
    "\n",
    "These algorithms are sometimes referred to as black-box optimization algorithms as they assume little or nothing (relative to the classical methods) about the objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Algorithms\n",
    "\n",
    "Stochastic optimization algorithms are algorithms that make use of randomness in the search procedure for objective functions for which derivatives cannot be calculated.\n",
    "\n",
    "Unlike the deterministic direct search methods, stochastic algorithms typically involve a lot more sampling of the objective function, but are able to handle problems with deceptive local optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optimization.sa as sa\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "# define objective function\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def cost(x):\n",
    "    return np.power(x, 2)[0]\n",
    "\n",
    "# plot the function\n",
    "x = np.linspace(-5,5,100)\n",
    "y = f(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.asarray([(-5.0, 5.0)])\n",
    "solution = sa.simulated_annealing(cost, bounds, n_iter=1000, debug=True)\n",
    "print(f'F({solution[0]})={f(solution[0])}')\n",
    "\n",
    "plt.plot(solution[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population Algorithms\n",
    "\n",
    "Population optimization algorithms are stochastic optimization algorithms that maintain a pool (a population) of candidate solutions that together are used to sample, explore, and hone in on an optima.\n",
    "\n",
    "Algorithms of this type are intended for more challenging objective problems that may have noisy function evaluations and many global optima (multimodal), and finding a good or good enough solution is challenging or infeasible using other methods.\n",
    "\n",
    "The pool of candidate solutions adds robustness to the search, increasing the likelihood of overcoming local optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimization.de as de\n",
    "bounds = np.asarray([(-5.0, 5.0)])\n",
    "solution = de.differential_evolution(cost, bounds, n_iter=10, debug=True)\n",
    "print(f'F({solution[0]})={f(solution[0])}')\n",
    "\n",
    "obj_best_iter, obj_avg_iter, obj_worst_iter = solution[2]\n",
    "\n",
    "plt.plot(obj_best_iter)\n",
    "plt.plot(obj_avg_iter)\n",
    "plt.plot(obj_worst_iter)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "222e38f7491daf337e0b1a0987736295e98828f490fd2b030e2ac9b1987b4fa0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
