{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_models_00.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPHRDBd1iwCfIcMFByZvCrb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ML 101\n","\n","## Classification\n","\n","In machine learning, classification refers to a predictive modeling problem where a class label is predicted for a given example of input data.\n","\n","Examples of classification problems include:\n","\n","- Given an example, classify if it is spam or not.\n","- Given a handwritten character, classify it as one of the known characters.\n","- Given recent user behavior, classify as churn or not.\n","\n","From a modeling perspective, classification requires a training dataset with many examples of inputs and outputs from which to learn.\n","\n","A model will use the training dataset and will calculate how to best map examples of input data to specific class labels. As such, the training dataset must be sufficiently representative of the problem and have many examples of each class label.\n","\n","There are many different types of classification algorithms for modeling classification predictive modeling problems.\n","\n","There are perhaps three main types of classification tasks that you may encounter; they are:\n","\n","1. Binary Classification\n","2. Multi-Class Classification\n","3. Multi-Label Classification\n","\n","### Binary Classification\n","\n","Binary classification refers to those classification tasks that have two class labels.\n","Typically, binary classification tasks involve one class that is the normal state and another class that is the abnormal state.\n","\n","### Multi-Class Classification\n","\n","Multi-class classification refers to those classification tasks that have more than two class labels.\n","\n","Unlike binary classification, multi-class classification does not have the notion of normal and abnormal outcomes. Instead, examples are classified as belonging to one among a range of known classes.\n","\n","The number of class labels may be very large on some problems. For example, a model may predict a photo as belonging to one among thousands or tens of thousands of faces in a face recognition system.\n","\n","### Multi-Label Classification\n","\n","Multi-label classification refers to those classification tasks that have two or more class labels, where one or more class labels may be predicted for each example.\n","\n","Consider the example of photo classification, where a given photo may have multiple objects in the scene and a model may predict the presence of multiple known objects in the photo, such as “bicycle”, “apple”, “person,” etc.\n","\n","This is unlike binary classification and multi-class classification, where a single class label is predicted for each example."],"metadata":{"id":"q5Lo96GBS3Jn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tg0WcF0l4eaW"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns"]},{"cell_type":"code","source":["def plot_decision_boundary(X, clf):\n","  x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n","  y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n","\n","  xx, yy = np.mgrid[x_min:x_max:.01, y_min:y_max:.01]\n","  grid = np.c_[xx.ravel(), yy.ravel()]\n","  probs = clf.predict_proba(grid)[:, 1].reshape(xx.shape)\n","\n","  f, ax = plt.subplots(figsize=(8, 6))\n","  contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\", vmin=0, vmax=1)\n","\n","  ax_c = f.colorbar(contour)\n","  ax_c.set_label(\"$P(y = 1)$\")\n","  ax_c.set_ticks([0, .25, .5, .75, 1])\n","\n","  ax.scatter(X[:,0], X[:, 1], c=y, s=50, cmap=\"RdBu\", vmin=-.2, vmax=1.2, edgecolor=\"white\", linewidth=1)\n","  ax.set(aspect=\"equal\", xlim=(x_min, x_max), ylim=(y_min, x_max), xlabel=\"$X_1$\", ylabel=\"$X_2$\")"],"metadata":{"id":"veMij97CXZCO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Linear Toy Dataset"],"metadata":{"id":"t3KSTEGBXS9s"}},{"cell_type":"code","source":["# import dataset\n","df = pd.read_csv('https://raw.githubusercontent.com/mariolpantunes/ml101/main/datasets/toy_dataset_00.csv')\n","# print the first rows of the dataset\n","df.head()"],"metadata":{"id":"eY9lqVzI4rDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.relplot(x=\"X1\", y=\"X2\", hue=\"Y\", data=df);"],"metadata":{"id":"Azi4txLE4-Jr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df[['X1', 'X2']].to_numpy()\n","y = df['Y'].to_numpy()"],"metadata":{"id":"W_tR_j3iYPo3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{"id":"Rh07vtlRYGK7"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","clf = LogisticRegression().fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"XTUpA6FuYLLv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Naive Bayes"],"metadata":{"id":"R-5SC5emYrAe"}},{"cell_type":"code","source":["from sklearn.naive_bayes import GaussianNB\n","\n","clf = GaussianNB().fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"u6KYWkIjYxtE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SVM\n","\n"],"metadata":{"id":"9Og-vwW3ZJzM"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","clf = SVC(probability=True, kernel='rbf').fit(X, y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"rE6Y5HOBZPN3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Neural Network"],"metadata":{"id":"uwFqyAfyZXNt"}},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","\n","clf = MLPClassifier(random_state=7, max_iter=5000).fit(X, y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"N0feIyOgZcyZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### KNN"],"metadata":{"id":"a0xx1n9aZj72"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","clf = KNeighborsClassifier(n_neighbors=1).fit(X, y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"baA9hgbEZmhU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decision Trees"],"metadata":{"id":"VWF0pUYLZs11"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","\n","clf = DecisionTreeClassifier().fit(X, y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"aadUXLYHZxRz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Random Forest"],"metadata":{"id":"GjWkzOlFZ54Y"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","clf = RandomForestClassifier(max_depth=10, random_state=0).fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"OASdtE8XEd5i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Gradient Boosting"],"metadata":{"id":"9n8UBMrcaEtD"}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","clf = GradientBoostingClassifier(random_state=0).fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"-xw5yonmaI-n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Voting Ensemble"],"metadata":{"id":"o3tR05ylbWoi"}},{"cell_type":"code","source":["from sklearn.ensemble import VotingClassifier\n","\n","c1 = LogisticRegression()\n","c2 = GaussianNB()\n","c3 = SVC(probability=True, kernel='rbf')\n","\n","clf = VotingClassifier([('lr', c1), ('nb', c2), ('svm', c3)], voting='soft').fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"UTR-Z51Zbh3o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Round Toy Dataset"],"metadata":{"id":"OMZHJnnocUQH"}},{"cell_type":"code","source":["# import dataset\n","df = pd.read_csv('https://raw.githubusercontent.com/mariolpantunes/ml101/main/datasets/toy_dataset_01.csv')\n","# print the first rows of the dataset\n","df.head()"],"metadata":{"id":"v6xQ2rH0cVTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.relplot(x=\"X1\", y=\"X2\", hue=\"Y\", data=df);"],"metadata":{"id":"m556qpDPcscT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df[['X1', 'X2']].to_numpy()\n","y = df['Y'].to_numpy()"],"metadata":{"id":"K-CdeCp8cu8f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{"id":"BoNq5GnAcylX"}},{"cell_type":"code","source":["clf = LogisticRegression().fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"YFvtQP17c2YG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Naive Bayes "],"metadata":{"id":"GTF11nBPc6MA"}},{"cell_type":"code","source":["clf = GaussianNB().fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"ZV1IXPQ8c-_h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SVM"],"metadata":{"id":"AXbukUKzdAzw"}},{"cell_type":"code","source":["clf = SVC(probability=True, kernel='rbf').fit(X, y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"oPBClXQddFO2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Neural Network"],"metadata":{"id":"2R9a9TNadIjc"}},{"cell_type":"code","source":["clf = MLPClassifier(random_state=7, max_iter=5000).fit(X, y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"GfdN63crdOrn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### KNN"],"metadata":{"id":"Z69mg59DdQ6A"}},{"cell_type":"code","source":["clf = KNeighborsClassifier(n_neighbors=3).fit(X, y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"KIdMiZnzdTc-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decision Trees"],"metadata":{"id":"L9ZDxU-PdYuX"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier().fit(X, y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"9sFXjZOsdbKq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Random Forest"],"metadata":{"id":"rg1-oQXfdfvN"}},{"cell_type":"code","source":["clf = RandomForestClassifier(max_depth=10, random_state=0).fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"PaMQNlD5dieY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Gradient Boosting"],"metadata":{"id":"L5FVAiuDdoPc"}},{"cell_type":"code","source":["clf = GradientBoostingClassifier(random_state=0).fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"3mF0WeyZduJh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Voting Ensemble"],"metadata":{"id":"HTG5p-iTdzBv"}},{"cell_type":"code","source":["c1 = LogisticRegression()\n","c2 = GaussianNB()\n","c3 = SVC(probability=True, kernel='rbf')\n","\n","clf = VotingClassifier([('lr', c1), ('nb', c2), ('svm', c3)], voting='soft').fit(X,y)\n","plot_decision_boundary(X, clf)"],"metadata":{"id":"YJcT907Md8Ob"},"execution_count":null,"outputs":[]}]}